# Shared environment variables for both React app and Python services
# Copy this file to .env and customize with your actual values
# WARNING: Never commit .env to version control - it contains secrets

# LLM Provider Settings
LLM_PROVIDER=openai
LLM_URL=https://api.openai.com/v1/chat/completions
LLM_MODEL=gpt-4o-mini
LLM_API_KEY=sk-your-openai-api-key-here
LLM_TEMPERATURE=0.4
LLM_KEEP_ALIVE=30m
LLM_THROTTLE_DELAY=0

# Frontend Training Controls
VITE_TRAINING_MAX_ATTEMPTS=5
VITE_DEBUG_MODE=false

# Service Ports
LLM_API_PORT=5001

# Alternative provider examples (uncomment and customize as needed):

# For OpenRouter:
# LLM_PROVIDER=openrouter
# LLM_URL=https://openrouter.ai/api/v1/chat/completions
# LLM_MODEL=anthropic/claude-3.5-sonnet
# LLM_API_KEY=sk-or-your-openrouter-key-here

# For Ollama (local):
# LLM_PROVIDER=ollama
# LLM_URL=http://localhost:11434/api/chat
# LLM_MODEL=llama3.2:3b
# LLM_API_KEY=
